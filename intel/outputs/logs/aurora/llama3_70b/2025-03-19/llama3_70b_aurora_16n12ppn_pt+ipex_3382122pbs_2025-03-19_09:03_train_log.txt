x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:05:15,987 - root - INFO - Starting job: Llama 3 70B training
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:05:15,988 - root - INFO - [GC] Initial GC collection. 0.00 seconds.
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:37,827 - root - INFO - Building 1-D device mesh with ['dp_shard'], [192]
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: 2025:03:19-09:08:37:(113693) |CCL_WARN| value of CCL_KVS_MODE changed to be mpi (default:pmi)
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: 2025:03:19-09:08:37:(113693) |CCL_WARN| value of CCL_KVS_CONNECTION_TIMEOUT changed to be 140 (default:120)
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: 2025:03:19-09:08:37:(113693) |CCL_WARN| value of CCL_PROCESS_LAUNCHER changed to be pmix (default:hydra)
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:42,823 - root - INFO - TikTokenizer built: #words 128256, BOS ID 128000, EOS ID 128001
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:42,823 - root - INFO - Preparing c4 dataset from /flare/Aurora_deployment/sgoswami/datavol/mldata/hf/c4
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:44,580 - root - INFO - Building llama3 70B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=8192, n_layers=80, n_heads=64, n_kv_heads=8, vocab_size=128256, multiple_of=4096, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, norm_type='rmsnorm')
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:45,114 - root - INFO - XPU capacity: Intel(R) Data Center GPU Max 1550 with 64.00GiB memory
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:45,687 - root - WARNING - Peak flops undefined for: Intel(R) Data Center GPU Max 1550, fallback to A100
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:45,689 - root - INFO - [34mModel llama3 70B [31msize: 70,553,706,496 total parameters[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:45,691 - root - INFO - Applied full activation checkpointing to the model
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:46,337 - root - INFO - Applied FSDP to the model
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:48,759 - root - WARNING - Peak flops undefined for: Intel(R) Data Center GPU Max 1550, fallback to A100
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:48,760 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:48,760 - root - INFO - XPU memory usage for model: 1.44GiB(2.26%)
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:48,762 - root - INFO - Trainer initialized.
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:08:48,762 - root - INFO - Training starts at step 1, with local batch size 8, global batch size 1536, sequence length 1024, total steps 1000 (warmup 200)
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:10:24,393 - root - INFO - [31mstep:  1  [32mloss: 12.2446  [33mmemory: 50.22GiB(78.47%)  [34mtps: 83  [36mtflops: 35.28  [35mmfu: 11.31%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:10:24,393 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:01:40
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:15:52,682 - root - INFO - [31mstep:  5  [32mloss: 10.9289  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.43  [35mmfu: 13.60%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:42,026 - root - INFO - [31mstep: 10  [32mloss: 11.0008  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.53  [35mmfu: 13.63%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:29:32,823 - root - INFO - [31mstep: 15  [32mloss:  9.4915  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.38  [35mmfu: 13.58%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:36:23,724 - root - INFO - [31mstep: 20  [32mloss:  8.8620  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.37  [35mmfu: 13.58%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:43:14,019 - root - INFO - [31mstep: 25  [32mloss:  8.3530  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.44  [35mmfu: 13.60%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:50:03,962 - root - INFO - [31mstep: 30  [32mloss:  7.9861  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.47  [35mmfu: 13.61%[39m
x4706c0s0b0n0.hostmgmt2706.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:56:53,695 - root - INFO - [31mstep: 35  [32mloss:  7.5756  [33mmemory: 51.83GiB(80.98%)  [34mtps: 100  [36mtflops: 42.49  [35mmfu: 13.62%[39m
