x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:28,418 - root - INFO - Starting job: Llama 3 70B training
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:28,419 - root - INFO - [GC] Initial GC collection. 0.00 seconds.
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:41,450 - root - INFO - Building 1-D device mesh with ['dp_shard'], [384]
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: 2025:03:19-09:22:41:(19864) |CCL_WARN| value of CCL_KVS_MODE changed to be mpi (default:pmi)
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: 2025:03:19-09:22:41:(19864) |CCL_WARN| value of CCL_KVS_CONNECTION_TIMEOUT changed to be 140 (default:120)
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: 2025:03:19-09:22:41:(19864) |CCL_WARN| value of CCL_PROCESS_LAUNCHER changed to be pmix (default:hydra)
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:47,588 - root - INFO - TikTokenizer built: #words 128256, BOS ID 128000, EOS ID 128001
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:47,588 - root - INFO - Preparing c4 dataset from /flare/Aurora_deployment/sgoswami/datavol/mldata/hf/c4
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:50,533 - root - INFO - Building llama3 70B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=8192, n_layers=80, n_heads=64, n_kv_heads=8, vocab_size=128256, multiple_of=4096, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=1024, depth_init=True, norm_type='rmsnorm')
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:50,882 - root - INFO - XPU capacity: Intel(R) Data Center GPU Max 1550 with 64.00GiB memory
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:50,947 - root - WARNING - Peak flops undefined for: Intel(R) Data Center GPU Max 1550, fallback to A100
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:50,949 - root - INFO - [34mModel llama3 70B [31msize: 70,553,706,496 total parameters[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:50,951 - root - INFO - Applied full activation checkpointing to the model
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:51,616 - root - INFO - Applied FSDP to the model
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:54,521 - root - WARNING - Peak flops undefined for: Intel(R) Data Center GPU Max 1550, fallback to A100
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:54,521 - root - INFO - Peak FLOPS used for computing MFU: 3.120e+14
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:54,521 - root - INFO - XPU memory usage for model: 0.77GiB(1.20%)
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:54,524 - root - INFO - Trainer initialized.
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:22:54,524 - root - INFO - Training starts at step 1, with local batch size 8, global batch size 3072, sequence length 1024, total steps 1000 (warmup 200)
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:25:33,610 - root - INFO - [31mstep:  1  [32mloss: 12.2551  [33mmemory: 49.17GiB(76.83%)  [34mtps: 50  [36mtflops: 21.41  [35mmfu: 6.86%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:25:33,611 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:01:40
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:35:26,117 - root - INFO - [31mstep:  5  [32mloss: 10.9831  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.51  [35mmfu: 7.53%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 09:47:43,640 - root - INFO - [31mstep: 10  [32mloss: 10.7795  [33mmemory: 50.79GiB(79.37%)  [34mtps: 56  [36mtflops: 23.61  [35mmfu: 7.57%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 10:00:06,398 - root - INFO - [31mstep: 15  [32mloss:  9.6647  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.44  [35mmfu: 7.51%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 10:12:26,897 - root - INFO - [31mstep: 20  [32mloss:  9.2579  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.51  [35mmfu: 7.54%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 10:24:52,953 - root - INFO - [31mstep: 25  [32mloss:  8.4228  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.34  [35mmfu: 7.48%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 10:37:20,862 - root - INFO - [31mstep: 30  [32mloss:  7.9421  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.28  [35mmfu: 7.46%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 10:49:45,691 - root - INFO - [31mstep: 35  [32mloss:  7.5508  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.38  [35mmfu: 7.49%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 11:02:14,882 - root - INFO - [31mstep: 40  [32mloss:  7.4066  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.24  [35mmfu: 7.45%[39m
x4207c1s4b0n0.hostmgmt2207.cm.aurora.alcf.anl.gov 0: [titan] 2025-03-19 11:14:45,690 - root - INFO - [31mstep: 45  [32mloss:  7.3000  [33mmemory: 50.79GiB(79.37%)  [34mtps: 55  [36mtflops: 23.19  [35mmfu: 7.43%[39m
