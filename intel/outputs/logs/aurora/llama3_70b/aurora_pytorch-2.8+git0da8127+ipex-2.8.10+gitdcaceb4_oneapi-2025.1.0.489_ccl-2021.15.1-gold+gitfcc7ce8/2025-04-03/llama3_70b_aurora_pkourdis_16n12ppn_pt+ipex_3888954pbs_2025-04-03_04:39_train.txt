[Intel] Running llama3_70b on Aurora system using 16 nodes with 12 processes per node
[Intel] Environment loaded from file /lus/flare/projects/Aurora_deployment/pkourdis/torchtitan/intel/envs/aurora/aurora_pytorch-2.8+git0da8127+ipex-2.8.10+gitdcaceb4_oneapi-2025.1.0.489_ccl-2021.15.1-gold+gitfcc7ce8.env
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:10,286 - root - INFO - Starting job: Llama 3 70B training
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:10,286 - root - INFO - [GC] Initial GC collection. 0.00 seconds.
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:11,160 - root - INFO - Building 1-D device mesh with ['dp_shard'], [192]
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: 2025:04:03-04:43:11:(84236) |CCL_WARN| value of CCL_KVS_MODE changed to be mpi (default:pmi)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: 2025:04:03-04:43:11:(84236) |CCL_WARN| value of CCL_KVS_CONNECTION_TIMEOUT changed to be 140 (default:120)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: 2025:04:03-04:43:11:(84236) |CCL_WARN| value of CCL_BCAST changed to be double_tree (default:)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: 2025:04:03-04:43:11:(84236) |CCL_WARN| value of CCL_ALLREDUCE_SCALEOUT changed to be direct (default:)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: 2025:04:03-04:43:11:(84236) |CCL_WARN| value of CCL_SYCL_SCALEOUT_HOST_BUF_SIZE changed to be 2147483648 (default:1073741824)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: 2025:04:03-04:43:11:(84236) |CCL_WARN| value of CCL_PROCESS_LAUNCHER changed to be pmix (default:hydra)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:25,387 - root - INFO - TikTokenizer built: #words 128256, BOS ID 128000, EOS ID 128001
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:25,387 - root - INFO - Preparing c4 dataset from /flare/Aurora_deployment/sgoswami/datavol/mldata/hf/c4
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:37,461 - root - INFO - Building llama3 70B with TransformerModelArgs(_enforced='This field is used to enforce all fields have defaults.', dim=8192, n_layers=80, n_heads=64, n_kv_heads=8, vocab_size=128256, multiple_of=4096, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000, max_seq_len=8192, depth_init=True, norm_type='rmsnorm', use_flex_attn=False)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:38,102 - root - INFO - XPU capacity: Intel(R) Data Center GPU Max 1550 with 64.00GiB memory
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:38,685 - root - INFO - [34mModel llama3 70B [31msize: 70,553,706,496 total parameters[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:38,686 - root - INFO - Applied full activation checkpointing to the model
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:39,401 - root - INFO - Applied FSDP to the model
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:42,773 - root - INFO - Peak FLOPS used for computing MFU: 2.982e+14
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:42,773 - root - INFO - XPU memory usage for model: 1.46GiB(2.28%)
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:42,776 - root - INFO - Trainer is initialized with local batch size 1, global batch size 192, sequence length 8192, total steps 10 (warmup 200).
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:43:42,776 - root - INFO - Training starts at step 1.
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:44:58,765 - root - INFO - [31mstep:  1  [32mloss: 12.2551  [33mmemory: 48.95GiB(76.48%)  [34mtps: 102  [36mtflops: 49.25  [35mmfu: 16.52%[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:44:58,766 - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:01:40
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:45:58,432 - root - INFO - [31mstep:  2  [32mloss: 12.0972  [33mmemory: 48.95GiB(76.48%)  [34mtps: 137  [36mtflops: 66.10  [35mmfu: 22.17%[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:47:56,523 - root - INFO - [31mstep:  4  [32mloss: 11.3120  [33mmemory: 48.95GiB(76.48%)  [34mtps: 139  [36mtflops: 66.80  [35mmfu: 22.40%[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:49:54,514 - root - INFO - [31mstep:  6  [32mloss: 11.4300  [33mmemory: 48.95GiB(76.48%)  [34mtps: 139  [36mtflops: 66.85  [35mmfu: 22.42%[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:51:52,409 - root - INFO - [31mstep:  8  [32mloss: 12.5948  [33mmemory: 48.95GiB(76.48%)  [34mtps: 139  [36mtflops: 66.91  [35mmfu: 22.44%[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:53:50,573 - root - INFO - [31mstep: 10  [32mloss: 10.6507  [33mmemory: 48.95GiB(76.48%)  [34mtps: 139  [36mtflops: 66.75  [35mmfu: 22.39%[39m
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:53:50,573 - root - INFO - Sleeping 2 seconds for other ranks to complete
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:53:52,574 - root - INFO - Training completed
x4709c5s4b0n0.hostmgmt2709.cm.aurora.alcf.anl.gov 0: [titan] 2025-04-03 04:53:52,574 - root - INFO - Process group destroyed.
